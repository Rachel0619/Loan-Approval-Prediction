{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q hillclimbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import Counter\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import plot_importance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from tqdm import tqdm\n",
    "# from hillclimbers import climb_hill, partial\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge original dataset\n",
    "# train_df = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\n",
    "# X_test = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\n",
    "# original_df = pd.read_csv('/kaggle/input/ps4e9-original-data-loan-approval-prediction/credit_risk_dataset.csv')\n",
    "# train_df = pd.concat([train_df, original_df], axis=0)\n",
    "# X_test_index = X_test['id']\n",
    "\n",
    "# merge original dataset\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "X_test = pd.read_csv(\"../data/test.csv\")\n",
    "original_df = pd.read_csv(\"../data/original.csv\")\n",
    "train_df = pd.concat([train_df, original_df], axis=0)\n",
    "X_test_index = X_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = train_df.select_dtypes(include=['object']).columns.to_list()\n",
    "\n",
    "# Remove 'loan_status' from the list\n",
    "if 'loan_status' in categorical_columns:  \n",
    "    categorical_columns.remove('loan_status')\n",
    "\n",
    "print(categorical_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = train_df.select_dtypes(include=['int', 'float']).columns.to_list()\n",
    "\n",
    "for column in ['id', 'loan_status']:\n",
    "    if column in numerical_columns:\n",
    "        numerical_columns.remove(column)\n",
    "    \n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Drop unique identifier (`id` column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['id'])\n",
    "X_test = X_test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in 'person_emp_length' and 'loan_int_rate'\n",
    "train_df = train_df.dropna(subset=['person_emp_length', 'loan_int_rate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set after dropping missing values: (87283, 12)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of train set after dropping missing values: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_age                    0\n",
       "person_income                 0\n",
       "person_home_ownership         0\n",
       "person_emp_length             0\n",
       "loan_intent                   0\n",
       "loan_grade                    0\n",
       "loan_amnt                     0\n",
       "loan_int_rate                 0\n",
       "loan_percent_income           0\n",
       "cb_person_default_on_file     0\n",
       "cb_person_cred_hist_length    0\n",
       "loan_status                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for missing value\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Drop rows with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "\n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "\n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n",
    "\n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "\n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)\n",
    "\n",
    "    return multiple_outliers\n",
    "\n",
    "\n",
    "# params dataset, number of outliers for rejection, list of features\n",
    "outliers_to_drop = detect_outliers(train_df, 1, numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated indices in train_df: 28638\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicated indices in train_df: {train_df.index.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3881 rows of outliers in the train set\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(outliers_to_drop)} rows of outliers in the train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set before dropping outliers: (87283, 12)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of train set before dropping outliers: {train_df.shape}')\n",
    "train_df = train_df.drop(outliers_to_drop, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set after dropping outliers: (80636, 12)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of train set after dropping outliers: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for col in numerical_columns:\n",
    "#     plt.figure(figsize=(8, 4))\n",
    "#     sns.histplot(train_df[col], kde=True, color='blue', label='Train')\n",
    "#     sns.histplot(X_test[col], kde=True, color='orange', label='Test')\n",
    "#     plt.title(f'Distribution of {col}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Split features with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['loan_status'])\n",
    "y_train = train_df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if X_train.shape[0] == y_train.shape[0]:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, features):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame, identifies non-numeric (categorical) columns,\n",
    "    applies one-hot encoding to them, and returns the modified DataFrame.\n",
    "    \"\"\"\n",
    "    for col in features:\n",
    "        df_dum = pd.get_dummies(df[col], prefix=col, dtype=int)\n",
    "        df = df.drop(col, axis=1)\n",
    "        df = pd.concat([df, df_dum], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "X_train = one_hot_encode(X_train, categorical_columns)\n",
    "X_test = one_hot_encode(X_test, categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Scaling Numerical Features before doing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(df_):\n",
    "    df = df_.copy()\n",
    "    df['interest_percent_income'] = round(df['loan_int_rate'] * df['loan_amnt'] / df['person_income'], 2)\n",
    "    df['zero_repayment_risk'] = np.where(df['loan_percent_income'] == 0, 1, 0)\n",
    "    # Calculate repayment_year normally for non-zero loan_percent_income\n",
    "    df['repayment_year'] = np.where(\n",
    "        df['loan_percent_income'] != 0,\n",
    "        df['loan_amnt'] / (df['loan_percent_income'] * df['person_income']),\n",
    "        np.nan  # Temporarily assign NaN for zero loan_percent_income\n",
    "    )\n",
    "    \n",
    "    # Calculate the 99th percentile of repayment_year for non-zero cases\n",
    "    high_quantile_value = df['repayment_year'].quantile(0.99)\n",
    "    \n",
    "    # Assign the high quantile value to repayment_year for cases with zero loan_percent_income\n",
    "    df['repayment_year'].fillna(high_quantile_value, inplace=True)\n",
    "    df['loan_to_income'] = df['loan_amnt'] / df['person_income']\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train = feature_generation(X_train)\n",
    "X_test = feature_generation(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80636, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data validation done: train set and test set are consistent\n"
     ]
    }
   ],
   "source": [
    "if X_train.shape[1] == X_test.shape[1]:\n",
    "    print('data validation done: train set and test set are consistent')\n",
    "else:\n",
    "    print('train set and test set are not consistent!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Balance the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common ways to handle imbalanced dataset:\n",
    "1. Random under-sampling\n",
    "2. Random over-sampling\n",
    "3. Synthetic over-sampling: SMOTE\n",
    "\n",
    "The method I choose here is SMOTE. I don't go with under-sampling because we don't have very large training set so I don't want to miss more information. Oversampling won't have this problem but it may suffer from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "sm = SMOTE(sampling_strategy=1, random_state=42, k_neighbors=3)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_res.copy()\n",
    "y = y_res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    67460\n",
       "1    67460\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134920, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# PCA_TR = PCA(n_components=15)\n",
    "# X_train_scaled = PCA_TR.fit_transform(X_train_scaled)\n",
    "\n",
    "# sum(PCA_TR.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# # select top 2 features using mutual_info_classif\n",
    "# selector = SelectKBest(mutual_info_classif, k=15)\n",
    "# X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# selected_features = selector.get_support(indices=True)\n",
    "# feature_names = X.columns[selected_features]  # Assuming X is a DataFrame with column names\n",
    "\n",
    "# print(\"Selected Features:\")\n",
    "# print(feature_names)\n",
    "\n",
    "# numerical_columns = [col for col in numerical_columns if col in selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[feature_names]\n",
    "# X_test = X_test[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "def model_training(model):\n",
    "    # Set the cross-validation parameters\n",
    "    n_splits = 5\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize arrays to store the OOF predictions and test predictions\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "    \n",
    "    # Initialize a list to store F1 scores of each fold\n",
    "    f1_scores = []\n",
    "\n",
    "    # Looping over cross-validation folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        print(f\"Training the Fold {fold+1}/{n_splits}\")\n",
    "\n",
    "        # Separate training and validation data\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        # Predictions on the validation set\n",
    "        val_preds_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        val_preds = (val_preds_proba >= 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "        oof_preds[val_idx] = val_preds_proba  # Store OOF predictions\n",
    "\n",
    "        # Predictions on the test set\n",
    "        test_preds += pipeline.predict_proba(X_test)[:, 1] / n_splits  # Average of predictions for each fold\n",
    "\n",
    "        # AUC and F1 Score evaluation for this fold\n",
    "        fold_auc = roc_auc_score(y_val, val_preds_proba)\n",
    "        fold_f1 = f1_score(y_val, val_preds)\n",
    "        f1_scores.append(fold_f1)\n",
    "\n",
    "        print(f\"AUC of Fold {fold+1}: {fold_auc:.5f}\")\n",
    "        print(f\"F1 Score of Fold {fold+1}: {fold_f1:.5f}\")\n",
    "\n",
    "    # AUC OOF Assessment\n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"AUC OOF: {oof_auc:.4f}\")\n",
    "\n",
    "    # Average F1 Score across all folds\n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    print(f\"Average F1 Score: {avg_f1_score:.4f}\")\n",
    "    \n",
    "    return oof_preds, test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = {}\n",
    "test_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Fold 1/5\n",
      "AUC of Fold 1: 0.99206\n",
      "F1 Score of Fold 1: 0.96798\n",
      "Training the Fold 2/5\n",
      "AUC of Fold 2: 0.99105\n",
      "F1 Score of Fold 2: 0.96677\n",
      "Training the Fold 3/5\n",
      "AUC of Fold 3: 0.99224\n",
      "F1 Score of Fold 3: 0.96874\n",
      "Training the Fold 4/5\n",
      "AUC of Fold 4: 0.99123\n",
      "F1 Score of Fold 4: 0.96831\n",
      "Training the Fold 5/5\n",
      "AUC of Fold 5: 0.99087\n",
      "F1 Score of Fold 5: 0.96586\n",
      "AUC OOF: 0.9915\n",
      "Average F1 Score: 0.9675\n"
     ]
    }
   ],
   "source": [
    "xgb_base_model = XGBClassifier()\n",
    "oof_preds[\"xgb_base_model\"], test_preds[\"xgb_base_model\"] = model_training(xgb_base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Model training and hyper tuning with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Xgboost + Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'device': 'cuda',\n",
    "        'eval_metric': 'auc',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'n_estimators': 1000,\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'verbosity': 0  # Suppress warnings and messages from XGBoost\n",
    "    }\n",
    "    \n",
    "    # Fitting LGBM model with parameters from the trials\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', XGBClassifier(**params))])\n",
    "    \n",
    "    # Stratified sampling \n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "    cv_splits = cv.split(X, y)\n",
    "    \n",
    "    # Creating empty scores list to hold AUC scores from each trialed model\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        score = roc_auc_score(y_val_fold, y_pred_proba)\n",
    "        scores.append(score)\n",
    "        \n",
    "    # Printing and returning mean AUC scores\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"Mean ROC AUC Score = {mean_score:.5f}\")\n",
    "    return mean_score\n",
    "\n",
    "# When set to True, optuna will create a study to find the optimal parameters\n",
    "train = False\n",
    "\n",
    "if train:\n",
    "    \n",
    "    # Each optuna study uses an independent sampler with a TPE algorithm\n",
    "    # For each trial, the TPE essentially uses Gaussian Mixture Models to identify the optimal parameter value\n",
    "    study = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=42), direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    print('Best value:', study.best_value)\n",
    "    print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Catboost + Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     # Define the hyperparameter search space for CatBoost\n",
    "#     params = {\n",
    "#         'loss_function': 'Logloss',  # For binary classification in CatBoost\n",
    "#         'eval_metric': 'AUC',  # CatBoost uses AUC directly as the eval metric\n",
    "#         \"iterations\": 1000,\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "#         \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "#         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "#         'random_seed': 42,\n",
    "#         'verbose': 0  # Suppresses CatBoost output\n",
    "#     }\n",
    "    \n",
    "#     # Fitting CatBoost model with parameters from the trials\n",
    "#     model = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', CatBoostClassifier(**params))])\n",
    "    \n",
    "#     # Stratified sampling \n",
    "#     cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "#     cv_splits = cv.split(X, y)\n",
    "    \n",
    "#     # Creating empty scores list to hold AUC scores from each trialed model\n",
    "#     scores = []\n",
    "#     for train_idx, val_idx in cv_splits:\n",
    "#         X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "#         model.fit(X_train_fold, y_train_fold)\n",
    "#         y_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "#         score = roc_auc_score(y_val_fold, y_pred_proba)\n",
    "#         scores.append(score)\n",
    "        \n",
    "#     # Printing and returning mean AUC scores\n",
    "#     mean_score = np.mean(scores)\n",
    "#     print(f\"Mean ROC AUC Score = {mean_score:.5f}\")\n",
    "#     return mean_score\n",
    "\n",
    "# # When set to True, optuna will create a study to find the optimal parameters\n",
    "# train = False\n",
    "\n",
    "# if train:\n",
    "    \n",
    "#     # Each optuna study uses an independent sampler with a TPE algorithm\n",
    "#     # For each trial, the TPE essentially uses Gaussian Mixture Models to identify the optimal parameter value\n",
    "#     study = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=42), direction=\"maximize\")\n",
    "#     study.optimize(objective, n_trials=100)\n",
    "#     print('Best value:', study.best_value)\n",
    "#     print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Model training and evaluation using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the parameters after training\n",
    "best_xgb_params = {\n",
    "    'learning_rate': 0.028797752657070342, \n",
    "    'max_depth': 8, \n",
    "    'subsample': 0.8918424713352255, \n",
    "    'colsample_bytree': 0.8550229885420852, \n",
    "    'lambda': 3.53875886477924, \n",
    "    'alpha': 0.0774211647399625}\n",
    "\n",
    "best_xgb_model = XGBClassifier(**best_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the parameters after training\n",
    "# best_catboost_params = {\n",
    "#     'learning_rate': 0.09891405348764155, \n",
    "#     'depth': 6, \n",
    "#     'subsample': 0.9809977898486224, \n",
    "#     'colsample_bylevel': 0.9847688177175966, \n",
    "#     'min_data_in_leaf': 90,\n",
    "#     'verbose': 0}\n",
    "\n",
    "# best_catboost_model = CatBoostClassifier(**best_catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model):\n",
    "    # Set the cross-validation parameters\n",
    "    n_splits = 5\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize the OOF array to store the predictions\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "    # Looping over cross-validation folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        print(f\"Training the Fold {fold+1}/{n_splits}\")\n",
    "\n",
    "        # Separate training and validation data\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Predictions on the validation set\n",
    "        val_preds = model.predict_proba(X_val)[:, 1]\n",
    "        oof_preds[val_idx] = val_preds  # Stores OOF predictions\n",
    "        \n",
    "        # Predictions on the test set\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits  # Average of predictions for each fold\n",
    "\n",
    "        # AUC evaluation for this fold\n",
    "        fold_auc = roc_auc_score(y_val, val_preds)\n",
    "        print(f\"AUC of Fold {fold+1}: {fold_auc:.5f}\")\n",
    "\n",
    "    # AUC OOF Assessment\n",
    "    oof_auc = roc_auc_score(y, oof_preds)\n",
    "    print(f\"AUC OOF: {oof_auc:.4f}\")\n",
    "    \n",
    "    return oof_preds, test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Fold 1/5\n",
      "AUC of Fold 1: 0.98574\n",
      "Training the Fold 2/5\n",
      "AUC of Fold 2: 0.98479\n",
      "Training the Fold 3/5\n",
      "AUC of Fold 3: 0.98577\n",
      "Training the Fold 4/5\n",
      "AUC of Fold 4: 0.98482\n",
      "Training the Fold 5/5\n",
      "AUC of Fold 5: 0.98463\n",
      "AUC OOF: 0.9851\n"
     ]
    }
   ],
   "source": [
    "oof_preds[\"XGBoost\"], test_preds[\"XGBoost\"] = model_training(best_xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Feature importance using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Explain model predictions using shap library:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer(best_xgb_model)\n\u001b[0;32m----> 5\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_importance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loan_approval_prediction/lib/python3.11/site-packages/shap/explainers/_tree.py:432\u001b[0m, in \u001b[0;36mTreeExplainer.shap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    430\u001b[0m     dmatrix_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_xgb_dmatrix_props\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m    431\u001b[0m     X \u001b[38;5;241m=\u001b[39m xgboost\u001b[38;5;241m.\u001b[39mDMatrix(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdmatrix_props)\n\u001b[0;32m--> 432\u001b[0m phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_contribs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapprox_contribs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapproximate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    437\u001b[0m     model_output_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moriginal_model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    438\u001b[0m         X, iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_iterations), output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    439\u001b[0m         validate_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/loan_approval_prediction/lib/python3.11/site-packages/xgboost/core.py:2385\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2382\u001b[0m shape \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(c_bst_ulong)()\n\u001b[1;32m   2383\u001b[0m dims \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m   2384\u001b[0m _check_call(\n\u001b[0;32m-> 2385\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_pystr_to_cstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2393\u001b[0m )\n\u001b[1;32m   2394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_importance = X\n",
    "\n",
    "# Explain model predictions using shap library:\n",
    "explainer = shap.TreeExplainer(best_xgb_model)\n",
    "shap_values = explainer.shap_values(X_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot summary_plot as barplot:\n",
    "shap.summary_plot(shap_values, X_importance, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([X_importance.columns.tolist(), shap_sum.tolist()]).T\n",
    "importance_df.columns = ['column_name', 'shap_importance']\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hill_climb_test_preds, _ = climb_hill(\n",
    "#     train=train_df,\n",
    "#     oof_pred_df=pd.DataFrame(oof_preds),\n",
    "#     test_pred_df=pd.DataFrame(test_preds),\n",
    "#     target=\"loan_status\",\n",
    "#     objective=\"maximize\",\n",
    "#     eval_metric=partial(roc_auc_score),\n",
    "#     negative_weights=True,\n",
    "#     precision=0.001,\n",
    "#     plot_hill=True,\n",
    "#     plot_hist=False,\n",
    "#     return_oof_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": X_test_index,\n",
    "    \"loan_status\": test_preds[\"XGBoost\"]\n",
    "})\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling the model file for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_xgb_model, open('../models/xgbmodel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9709193,
     "sourceId": 84894,
     "sourceType": "competition"
    },
    {
     "datasetId": 5796052,
     "sourceId": 9519882,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:loan_approval_prediction]",
   "language": "python",
   "name": "conda-env-loan_approval_prediction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
